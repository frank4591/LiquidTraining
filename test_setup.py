#!/usr/bin/env python3
"""
Test script to verify LFM2-VL-1.6B setup
"""

import os
import sys
import torch

def test_dependencies():
    """Test if all required dependencies are available"""
    print("ğŸ” Testing dependencies...")
    
    try:
        import transformers
        print(f"âœ… Transformers: {transformers.__version__}")
    except ImportError:
        print("âŒ Transformers not found")
        return False
    
    try:
        import PIL
        print(f"âœ… PIL/Pillow: {PIL.__version__}")
    except ImportError:
        print("âŒ PIL/Pillow not found")
        return False
    
    try:
        import huggingface_hub
        print(f"âœ… HuggingFace Hub: {huggingface_hub.__version__}")
    except ImportError:
        print("âŒ HuggingFace Hub not found")
        return False
    
    print(f"âœ… PyTorch: {torch.__version__}")
    print(f"âœ… CUDA available: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"âœ… CUDA device: {torch.cuda.get_device_name()}")
        print(f"âœ… CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    
    return True

def test_model_path():
    """Test if the model path exists"""
    print("\nğŸ” Testing model path...")
    
    model_path = "./lfm2_vl_1_6b_model"
    
    if os.path.exists(model_path):
        print(f"âœ… Model path exists: {model_path}")
        
        # Check for key files
        required_files = ["config.json", "pytorch_model.bin", "tokenizer.json"]
        for file in required_files:
            file_path = os.path.join(model_path, file)
            if os.path.exists(file_path):
                print(f"âœ… Found: {file}")
            else:
                print(f"âš ï¸  Missing: {file}")
        
        return True
    else:
        print(f"âŒ Model path not found: {model_path}")
        print("ğŸ’¡ Run 'python save_lfm2_vl_model.py' first to download the model")
        return False

def test_basic_inference():
    """Test basic inference if model is available"""
    print("\nğŸ” Testing basic inference...")
    
    if not test_model_path():
        return False
    
    try:
        from transformers import AutoProcessor, AutoModelForImageTextToText
        
        print("Loading model...")
        processor = AutoProcessor.from_pretrained(
            "./lfm2_vl_1_6b_model", 
            trust_remote_code=True
        )
        
        model = AutoModelForImageTextToText.from_pretrained(
            "./lfm2_vl_1_6b_model",
            device_map="auto",
            torch_dtype="bfloat16",
            trust_remote_code=True
        )
        
        print("âœ… Model loaded successfully!")
        print(f"âœ… Model device: {model.device}")
        print(f"âœ… Model dtype: {model.dtype}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error testing inference: {str(e)}")
        return False

def main():
    """Main test function"""
    print("ğŸš€ LFM2-VL-1.6B Setup Test")
    print("=" * 50)
    
    # Test dependencies
    deps_ok = test_dependencies()
    
    # Test model path
    model_ok = test_model_path()
    
    # Test inference if possible
    inference_ok = False
    if deps_ok and model_ok:
        inference_ok = test_basic_inference()
    
    # Summary
    print("\n" + "=" * 50)
    print("ğŸ“Š TEST SUMMARY")
    print("=" * 50)
    
    print(f"Dependencies: {'âœ… PASS' if deps_ok else 'âŒ FAIL'}")
    print(f"Model files: {'âœ… PASS' if model_ok else 'âŒ FAIL'}")
    print(f"Inference: {'âœ… PASS' if inference_ok else 'âŒ FAIL'}")
    
    if deps_ok and model_ok and inference_ok:
        print("\nğŸ‰ All tests passed! You're ready to use LFM2-VL-1.6B")
        print("ğŸ’¡ Try: python instagram_caption_generator.py --image ../img1.jpg")
    else:
        print("\nâš ï¸  Some tests failed. Please check the issues above.")
        
        if not deps_ok:
            print("ğŸ’¡ Install dependencies: pip install -r requirements.txt")
        
        if not model_ok:
            print("ğŸ’¡ Download model: python save_lfm2_vl_model.py")
    
    return 0

if __name__ == "__main__":
    exit(main())
